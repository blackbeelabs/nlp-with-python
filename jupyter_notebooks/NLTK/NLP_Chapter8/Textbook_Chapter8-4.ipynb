{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.4 Parsing with Context-Free Grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#S can be broken down to NP, followed by VP\n",
    "#VP can be broken down to V followed by NP, or V followed by NP followed by PP\n",
    "#PP can be broken down to P followed by NP\n",
    "grammar1 = nltk.CFG.fromstring(\"\"\"\n",
    "  S -> NP VP              \n",
    "  VP -> V NP | V NP PP    \n",
    "  PP -> P NP              \n",
    "  V -> \"saw\" | \"ate\" | \"walked\"\n",
    "  NP -> \"John\" | \"Mary\" | \"Bob\" | Det N | Det N PP\n",
    "  Det -> \"a\" | \"an\" | \"the\" | \"my\"\n",
    "  N -> \"man\" | \"dog\" | \"cat\" | \"telescope\" | \"park\"\n",
    "  P -> \"in\" | \"on\" | \"by\" | \"with\"\n",
    "  \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Descent Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing 'Mary saw a dog'\n",
      "    [ * S ]\n",
      "  E [ * NP VP ]\n",
      "  E [ * 'John' VP ]\n",
      "  E [ * 'Mary' VP ]\n",
      "  M [ 'Mary' * VP ]\n",
      "  E [ 'Mary' * V NP ]\n",
      "  E [ 'Mary' * 'saw' NP ]\n",
      "  M [ 'Mary' 'saw' * NP ]\n",
      "  E [ 'Mary' 'saw' * 'John' ]\n",
      "  E [ 'Mary' 'saw' * 'Mary' ]\n",
      "  E [ 'Mary' 'saw' * 'Bob' ]\n",
      "  E [ 'Mary' 'saw' * Det N ]\n",
      "  E [ 'Mary' 'saw' * 'a' N ]\n",
      "  M [ 'Mary' 'saw' 'a' * N ]\n",
      "  E [ 'Mary' 'saw' 'a' * 'man' ]\n",
      "  E [ 'Mary' 'saw' 'a' * 'dog' ]\n",
      "  M [ 'Mary' 'saw' 'a' 'dog' ]\n",
      "  + [ 'Mary' 'saw' 'a' 'dog' ]\n",
      "(S (NP Mary) (VP (V saw) (NP (Det a) (N dog))))\n",
      "\n",
      "  E [ 'Mary' 'saw' 'a' * 'cat' ]\n",
      "  E [ 'Mary' 'saw' 'a' * 'telescope' ]\n",
      "  E [ 'Mary' 'saw' 'a' * 'park' ]\n",
      "  E [ 'Mary' 'saw' * 'an' N ]\n",
      "  E [ 'Mary' 'saw' * 'the' N ]\n",
      "  E [ 'Mary' 'saw' * 'my' N ]\n",
      "  E [ 'Mary' 'saw' * Det N PP ]\n",
      "  E [ 'Mary' 'saw' * 'a' N PP ]\n",
      "  M [ 'Mary' 'saw' 'a' * N PP ]\n",
      "  E [ 'Mary' 'saw' 'a' * 'man' PP ]\n",
      "  E [ 'Mary' 'saw' 'a' * 'dog' PP ]\n",
      "  M [ 'Mary' 'saw' 'a' 'dog' * PP ]\n",
      "  E [ 'Mary' 'saw' 'a' 'dog' * P NP ]\n",
      "  E [ 'Mary' 'saw' 'a' 'dog' * 'in' NP ]\n",
      "  E [ 'Mary' 'saw' 'a' 'dog' * 'on' NP ]\n",
      "  E [ 'Mary' 'saw' 'a' 'dog' * 'by' NP ]\n",
      "  E [ 'Mary' 'saw' 'a' 'dog' * 'with' NP ]\n",
      "  E [ 'Mary' 'saw' 'a' * 'cat' PP ]\n",
      "  E [ 'Mary' 'saw' 'a' * 'telescope' PP ]\n",
      "  E [ 'Mary' 'saw' 'a' * 'park' PP ]\n",
      "  E [ 'Mary' 'saw' * 'an' N PP ]\n",
      "  E [ 'Mary' 'saw' * 'the' N PP ]\n",
      "  E [ 'Mary' 'saw' * 'my' N PP ]\n",
      "  E [ 'Mary' * 'ate' NP ]\n",
      "  E [ 'Mary' * 'walked' NP ]\n",
      "  E [ 'Mary' * V NP PP ]\n",
      "  E [ 'Mary' * 'saw' NP PP ]\n",
      "  M [ 'Mary' 'saw' * NP PP ]\n",
      "  E [ 'Mary' 'saw' * 'John' PP ]\n",
      "  E [ 'Mary' 'saw' * 'Mary' PP ]\n",
      "  E [ 'Mary' 'saw' * 'Bob' PP ]\n",
      "  E [ 'Mary' 'saw' * Det N PP ]\n",
      "  E [ 'Mary' 'saw' * 'a' N PP ]\n",
      "  M [ 'Mary' 'saw' 'a' * N PP ]\n",
      "  E [ 'Mary' 'saw' 'a' * 'man' PP ]\n",
      "  E [ 'Mary' 'saw' 'a' * 'dog' PP ]\n",
      "  M [ 'Mary' 'saw' 'a' 'dog' * PP ]\n",
      "  E [ 'Mary' 'saw' 'a' 'dog' * P NP ]\n",
      "  E [ 'Mary' 'saw' 'a' 'dog' * 'in' NP ]\n",
      "  E [ 'Mary' 'saw' 'a' 'dog' * 'on' NP ]\n",
      "  E [ 'Mary' 'saw' 'a' 'dog' * 'by' NP ]\n",
      "  E [ 'Mary' 'saw' 'a' 'dog' * 'with' NP ]\n",
      "  E [ 'Mary' 'saw' 'a' * 'cat' PP ]\n",
      "  E [ 'Mary' 'saw' 'a' * 'telescope' PP ]\n",
      "  E [ 'Mary' 'saw' 'a' * 'park' PP ]\n",
      "  E [ 'Mary' 'saw' * 'an' N PP ]\n",
      "  E [ 'Mary' 'saw' * 'the' N PP ]\n",
      "  E [ 'Mary' 'saw' * 'my' N PP ]\n",
      "  E [ 'Mary' 'saw' * Det N PP PP ]\n",
      "  E [ 'Mary' 'saw' * 'a' N PP PP ]\n",
      "  M [ 'Mary' 'saw' 'a' * N PP PP ]\n",
      "  E [ 'Mary' 'saw' 'a' * 'man' PP PP ]\n",
      "  E [ 'Mary' 'saw' 'a' * 'dog' PP PP ]\n",
      "  M [ 'Mary' 'saw' 'a' 'dog' * PP PP ]\n",
      "  E [ 'Mary' 'saw' 'a' 'dog' * P NP PP ]\n",
      "  E [ 'Mary' 'saw' 'a' 'dog' * 'in' NP PP ]\n",
      "  E [ 'Mary' 'saw' 'a' 'dog' * 'on' NP PP ]\n",
      "  E [ 'Mary' 'saw' 'a' 'dog' * 'by' NP PP ]\n",
      "  E [ 'Mary' 'saw' 'a' 'dog' * 'with' NP PP ]\n",
      "  E [ 'Mary' 'saw' 'a' * 'cat' PP PP ]\n",
      "  E [ 'Mary' 'saw' 'a' * 'telescope' PP PP ]\n",
      "  E [ 'Mary' 'saw' 'a' * 'park' PP PP ]\n",
      "  E [ 'Mary' 'saw' * 'an' N PP PP ]\n",
      "  E [ 'Mary' 'saw' * 'the' N PP PP ]\n",
      "  E [ 'Mary' 'saw' * 'my' N PP PP ]\n",
      "  E [ 'Mary' * 'ate' NP PP ]\n",
      "  E [ 'Mary' * 'walked' NP PP ]\n",
      "  E [ * 'Bob' VP ]\n",
      "  E [ * Det N VP ]\n",
      "  E [ * 'a' N VP ]\n",
      "  E [ * 'an' N VP ]\n",
      "  E [ * 'the' N VP ]\n",
      "  E [ * 'my' N VP ]\n",
      "  E [ * Det N PP VP ]\n",
      "  E [ * 'a' N PP VP ]\n",
      "  E [ * 'an' N PP VP ]\n",
      "  E [ * 'the' N PP VP ]\n",
      "  E [ * 'my' N PP VP ]\n"
     ]
    }
   ],
   "source": [
    "rd_parser = nltk.RecursiveDescentParser(grammar1, trace=2) #Trace = 2 provides the full parsing steps\n",
    "sent = \"Mary saw a dog\".split()\n",
    "for t in rd_parser.parse(sent):\n",
    "    print(t)\n",
    "    print()\n",
    "#Observations: \n",
    "#1. The parser actually reads the grammar and parses the sentence according to that.\n",
    "#2. It starts with S -> NP, VP followed by NP -> John etc.\n",
    "\n",
    "#The second part demonstrates all the valid sentences with that vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shift Reduce Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing 'Mary saw a dog'\n",
      "    [ * Mary saw a dog]\n",
      "  S [ 'Mary' * saw a dog]\n",
      "  R [ NP * saw a dog]\n",
      "  S [ NP 'saw' * a dog]\n",
      "  R [ NP V * a dog]\n",
      "  S [ NP V 'a' * dog]\n",
      "  R [ NP V Det * dog]\n",
      "  S [ NP V Det 'dog' * ]\n",
      "  R [ NP V Det N * ]\n",
      "  R [ NP V NP * ]\n",
      "  R [ NP VP * ]\n",
      "  R [ S * ]\n",
      "(S (NP Mary) (VP (V saw) (NP (Det a) (N dog))))\n"
     ]
    }
   ],
   "source": [
    "#Shift-Reduce Parser\n",
    "sr_parser = nltk.ShiftReduceParser(grammar1, trace=2)\n",
    "for t in sr_parser.parse(sent):\n",
    "    print(t)\n",
    "#From here you can see shift steps and reduce steps very clearly, with the * as the separator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Well-formed Substring Tables (WFST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Init_Wfst function\n",
    "def init_wfst(tokens, grammar):\n",
    "    numtokens = len(tokens)\n",
    "    wfst = [[None for i in range(numtokens+1)] for j in range(numtokens+1)]\n",
    "    for i in range(numtokens):\n",
    "        productions = grammar.productions(rhs=tokens[i])\n",
    "        wfst[i][i+1] = productions[0].lhs()\n",
    "    return wfst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_wfst(wfst, tokens, grammar, trace=False):\n",
    "    index = dict((p.rhs(), p.lhs()) for p in grammar.productions())\n",
    "    numtokens = len(tokens)\n",
    "    for span in range(2, numtokens+1):\n",
    "        for start in range(numtokens+1-span):\n",
    "            end = start + span\n",
    "            for mid in range(start+1, end):\n",
    "                nt1, nt2 = wfst[start][mid], wfst[mid][end]\n",
    "                if nt1 and nt2 and (nt1,nt2) in index:\n",
    "                    wfst[start][end] = index[(nt1, nt2)]\n",
    "                    if trace:\n",
    "                        print(\"[%s] %3s [%s] %3s [%s] ==> [%s] %3s [%s]\" % \\\n",
    "                              (start, nt1, mid, nt2, end, start, index[(nt1, nt2)], end))\n",
    "    return wfst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(wfst, tokens):\n",
    "    print('\\nWFST  ' + ' '.join((\"%-4d\" % i) for i in range(1, len(wfst))))\n",
    "    for i in range(len(wfst)-1):\n",
    "        print(\"%d     \" % i, end = \" \")\n",
    "        for j in range(1, len(wfst)):\n",
    "            print(\"%-4s\" % (wfst[i][j] or \".\"), end =\" \")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Given a sentence $a_1, \\cdots, a_n$ with $n$ words, instantiate a triangular matrix $A$ where $A$ has $n$ rows and $n$ columns. The rows are labelled $\\left\\{ 0, \\cdots, n-1 \\right\\}$ and the columns are labelled $\\left\\{ 1, \\cdots, n \\right\\}$\n",
    "\n",
    "2. Assign the cells in $A$ for each word $a_i,i \\in [1, \\cdots, n]$ where the horizontal axis represents the start position of the string and the vertical axis represents the end position of the string. The cell will have the value of **the word category of the word*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 1:\n",
    "\n",
    "Given the sentence `'I', 'shot', 'an', 'elephant', 'in', 'my', 'pajamas'`, the representation of the word `shot` in $A$ appears in position $(1, 2)$. Since `shot` belongs to the category `v`, the cell $(1, 2)$ contains the value `v`. This way, for every word in the sentence, we can look up which grammar category it belongs to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WFST  1    2    3    4    5    6    7   \n",
      "0      NP   .    .    .    .    .    .    \n",
      "1      .    V    .    .    .    .    .    \n",
      "2      .    .    Det  .    .    .    .    \n",
      "3      .    .    .    N    .    .    .    \n",
      "4      .    .    .    .    P    .    .    \n",
      "5      .    .    .    .    .    Det  .    \n",
      "6      .    .    .    .    .    .    N    \n"
     ]
    }
   ],
   "source": [
    "from nltk import CFG\n",
    "groucho_grammar = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "PP -> P NP\n",
    "NP -> Det N | Det N PP | 'I'\n",
    "VP -> V NP | VP PP\n",
    "Det -> 'an' | 'my'\n",
    "N -> 'elephant' | 'pajamas'\n",
    "V -> 'shot'\n",
    "P -> 'in'\n",
    " \"\"\")\n",
    "tokens = \"I shot an elephant in my pajamas\".split()\n",
    "wfst0 = init_wfst(tokens, groucho_grammar)\n",
    "display(wfst0, tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can fill in a value in $A_{(i, j)}$ if there is a production $A \\rightarrow B C$ and we find a non-terminal (not-at-the-end) $B$ in $(i, k)$ and $C$ in $(k, j)$. For example, $NP \\rightarrow Det\\space N$ exists in the grammar. Hence, we can put $NP$ in cell $(2, 4)$. An $NP$ exists in the starting position of $2$ and ends at $4$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WFST  1    2    3    4    5    6    7   \n",
      "0      NP   .    .    S    .    .    S    \n",
      "1      .    V    .    VP   .    .    VP   \n",
      "2      .    .    Det  NP   .    .    .    \n",
      "3      .    .    .    N    .    .    .    \n",
      "4      .    .    .    .    P    .    PP   \n",
      "5      .    .    .    .    .    Det  NP   \n",
      "6      .    .    .    .    .    .    N    \n"
     ]
    }
   ],
   "source": [
    "#Given the same logic, there is a production of \n",
    "#VP -> V NP resulting in VP in (1, 4) and\n",
    "#S -> NP VP resulting in S in (0, 4) and so on and so forth.\n",
    "wfst1 = complete_wfst(wfst0, tokens, groucho_grammar)\n",
    "display(wfst1, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2] Det [3]   N [4] ==> [2]  NP [4]\n",
      "[5] Det [6]   N [7] ==> [5]  NP [7]\n",
      "[1]   V [2]  NP [4] ==> [1]  VP [4]\n",
      "[4]   P [5]  NP [7] ==> [4]  PP [7]\n",
      "[0]  NP [1]  VP [4] ==> [0]   S [4]\n",
      "[1]  VP [4]  PP [7] ==> [1]  VP [7]\n",
      "[0]  NP [1]  VP [7] ==> [0]   S [7]\n"
     ]
    }
   ],
   "source": [
    "wfst1 = complete_wfst(wfst0, tokens, groucho_grammar, trace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
