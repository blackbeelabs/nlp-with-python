{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.3 - Extending a Feature-Based Grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subcategorization\n",
    "\n",
    "Earlier, we used category labels to represent different types of verbs, in particular `IV` for intransitive verbs and `TV` for transitive verbs. This allowed us to write the following:\n",
    "\n",
    "```\n",
    "VP -> IV\n",
    "VP -> TV NP\n",
    "```\n",
    "Although `IV` and `TV` are two different kinds of `V`, they are just atomic, non-terminal symbols in a CFG and are distinct from each other as symbols. This notation, however, does not let us say anything about verbs in general. e.g. we cannot say \"All lexical items of category `V` can be marked for tense.\" \n",
    "\n",
    "For example we cannot assign a `tense` feature in `walk` because it's an `IV` not a `V`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple approach called **Generalized Phrase Structure Grammar** tries to solve this problem by having lexical categories have a `SUBCAT` feture, which tells what subcategory it belongs to. The following example uses a more mnemonic values, namely `intrans`, `trans` and `clause`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VP[TENSE=?t, NUM=?n] -> V[SUBCAT=intrans, TENSE=?t, NUM=?n]\n",
      "VP[TENSE=?t, NUM=?n] -> V[SUBCAT=trans, TENSE=?t, NUM=?n] NP\n",
      "VP[TENSE=?t, NUM=?n] -> V[SUBCAT=clause, TENSE=?t, NUM=?n] SBar\n",
      "\n",
      "V[SUBCAT=intrans, TENSE=pres, NUM=sg] -> 'disappears' | 'walks'\n",
      "V[SUBCAT=trans, TENSE=pres, NUM=sg] -> 'sees' | 'likes'\n",
      "V[SUBCAT=clause, TENSE=pres, NUM=sg] -> 'says' | 'claims'\n",
      "\n",
      "V[SUBCAT=intrans, TENSE=pres, NUM=pl] -> 'disappear' | 'walk'\n",
      "V[SUBCAT=trans, TENSE=pres, NUM=pl] -> 'see' | 'like'\n",
      "V[SUBCAT=clause, TENSE=pres, NUM=pl] -> 'say' | 'claim'\n",
      "\n",
      "V[SUBCAT=intrans, TENSE=past] -> 'disappeared' | 'walked'\n",
      "V[SUBCAT=trans, TENSE=past] -> 'saw' | 'liked'\n",
      "V[SUBCAT=clause, TENSE=past] -> 'said' | 'claimed'\n"
     ]
    }
   ],
   "source": [
    "print(\"VP[TENSE=?t, NUM=?n] -> V[SUBCAT=intrans, TENSE=?t, NUM=?n]\")\n",
    "print(\"VP[TENSE=?t, NUM=?n] -> V[SUBCAT=trans, TENSE=?t, NUM=?n] NP\")\n",
    "print(\"VP[TENSE=?t, NUM=?n] -> V[SUBCAT=clause, TENSE=?t, NUM=?n] SBar\")\n",
    "print()\n",
    "print(\"V[SUBCAT=intrans, TENSE=pres, NUM=sg] -> 'disappears' | 'walks'\")\n",
    "print(\"V[SUBCAT=trans, TENSE=pres, NUM=sg] -> 'sees' | 'likes'\")\n",
    "print(\"V[SUBCAT=clause, TENSE=pres, NUM=sg] -> 'says' | 'claims'\")\n",
    "print()\n",
    "print(\"V[SUBCAT=intrans, TENSE=pres, NUM=pl] -> 'disappear' | 'walk'\")\n",
    "print(\"V[SUBCAT=trans, TENSE=pres, NUM=pl] -> 'see' | 'like'\")\n",
    "print(\"V[SUBCAT=clause, TENSE=pres, NUM=pl] -> 'say' | 'claim'\")\n",
    "print()\n",
    "print(\"V[SUBCAT=intrans, TENSE=past] -> 'disappeared' | 'walked'\")\n",
    "print(\"V[SUBCAT=trans, TENSE=past] -> 'saw' | 'liked'\")\n",
    "print(\"V[SUBCAT=clause, TENSE=past] -> 'said' | 'claimed'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we see a lexical category like `V[SUBCAT=trans]`, we can interpret the `SUBCAT` specification as a pointer to a production in which `V[SUBCAT=trans]` is introduced as the head child in a `VP` production. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heads Revisited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X-bar syntax abstracts out the notion of **phrasal level**. It is usual to recognize three such levels. If `N` represents the lexical level, then `N'` represents the next level up, corresponding to the more traditional category `Nom` and `N''` represents the phrasal level, corresponding to the category `NP`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary Verbs and Inversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inverted clauses, where the order of the subject and verb is switched, occur in English interrogatives and also after \"negative\" adverbs:\n",
    "\n",
    "* Do you like children?\n",
    "* Can Jody walk?\n",
    "\n",
    "\n",
    "* Rarely do you see Kim\n",
    "* Never have I seen this dog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However we cannot place just any verb in pre-subject position:\n",
    "* Like you children\n",
    "* Walks Jody?\n",
    "\n",
    "\n",
    "* Rarely see you Kim\n",
    "* Never saw I this dog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unbounded Dependency Constructions\n",
    "\n",
    "Consider the following contrasts:\n",
    "\n",
    "* You like Jody\n",
    "* You like.\n",
    "\n",
    "\n",
    "* You put the card into the slot.\n",
    "* You put into the slot.\n",
    "* You put the card.\n",
    "* You put."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The verb `like` requires an `NP` complement, while `put` requires both a following `NP` and `PP`. Omitting them results in ungrammaticality. Yet there are contexts in which obligatory complements can be omitted like:\n",
    "\n",
    "* Kim knows who you like.\n",
    "* This music, you really like.\n",
    "\n",
    "\n",
    "* Which card do you put into the slot?\n",
    "* Which slot do you put the card into?\n",
    "\n",
    "That is, an obligatory complement can be omitted if there is an appropriate **filler** in the sentence, such as the question word *who* in `Kim knows who you like.`, the preposed topic `this music` in `This music, you really like.` or the `wh` phrases in `which card/slot`. It is common to say that sentences like those contain **gaps** where the obligatory complements have been omitted, and these gaps are sometimes made explicit using an underscore:\n",
    "\n",
    "1. Which card do you put __ into the slot?\n",
    "2. Which slot do you put the card into __?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So a gap can occur if it is licensed by a filler. Converse fillers can only occur only if there is an appropriate gap elsewhere in the sentence, as shown by the following examples:\n",
    "\n",
    "1. Kim knows who you like Jody.\n",
    "2. This music, you really like hip-hop\n",
    "3. Which card do you put this into the slot?\n",
    "4. Which slot do you put the card into this one?\n",
    "\n",
    "The co-occurrence between filler and gap is called a \"dependency\". There is **no upper bound between filler and gap**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% start S\n",
      "# ###################\n",
      "# Grammar Productions\n",
      "# ###################\n",
      "S[-INV] -> NP VP\n",
      "S[-INV]/?x -> NP VP/?x\n",
      "S[-INV] -> NP S/NP\n",
      "S[-INV] -> Adv[+NEG] S[+INV]\n",
      "S[+INV] -> V[+AUX] NP VP\n",
      "S[+INV]/?x -> V[+AUX] NP VP/?x\n",
      "SBar -> Comp S[-INV]\n",
      "SBar/?x -> Comp S[-INV]/?x\n",
      "VP -> V[SUBCAT=intrans, -AUX]\n",
      "VP -> V[SUBCAT=trans, -AUX] NP\n",
      "VP/?x -> V[SUBCAT=trans, -AUX] NP/?x\n",
      "VP -> V[SUBCAT=clause, -AUX] SBar\n",
      "VP/?x -> V[SUBCAT=clause, -AUX] SBar/?x\n",
      "VP -> V[+AUX] VP\n",
      "VP/?x -> V[+AUX] VP/?x\n",
      "# ###################\n",
      "# Lexical Productions\n",
      "# ###################\n",
      "V[SUBCAT=intrans, -AUX] -> 'walk' | 'sing'\n",
      "V[SUBCAT=trans, -AUX] -> 'see' | 'like'\n",
      "V[SUBCAT=clause, -AUX] -> 'say' | 'claim'\n",
      "V[+AUX] -> 'do' | 'can'\n",
      "NP[-WH] -> 'you' | 'cats'\n",
      "NP[+WH] -> 'who'\n",
      "Adv[+NEG] -> 'rarely' | 'never'\n",
      "NP/NP ->\n",
      "Comp -> 'that'\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.data.show_cfg(\"grammars/book_grammars/feat1.fcfg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S[-INV]\n",
      "  (NP[+WH] who)\n",
      "  (S[+INV]/NP[]\n",
      "    (V[+AUX] do)\n",
      "    (NP[-WH] you)\n",
      "    (VP[]/NP[]\n",
      "      (V[-AUX, SUBCAT='clause'] claim)\n",
      "      (SBar[]/NP[]\n",
      "        (Comp[] that)\n",
      "        (S[-INV]/NP[]\n",
      "          (NP[-WH] you)\n",
      "          (VP[]/NP[] (V[-AUX, SUBCAT='trans'] like) (NP[]/NP[] )))))))\n"
     ]
    }
   ],
   "source": [
    "tokens = \"who do you claim that you like\".split()\n",
    "from nltk import load_parser\n",
    "cp = load_parser(\"grammars/book_grammars/feat1.fcfg\")\n",
    "for tree in cp.parse(tokens):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S[-INV]\n",
      "  (NP[-WH] you)\n",
      "  (VP[]\n",
      "    (V[-AUX, SUBCAT='clause'] claim)\n",
      "    (SBar[]\n",
      "      (Comp[] that)\n",
      "      (S[-INV]\n",
      "        (NP[-WH] you)\n",
      "        (VP[] (V[-AUX, SUBCAT='trans'] like) (NP[-WH] cats))))))\n"
     ]
    }
   ],
   "source": [
    "tokens2 = 'you claim that you like cats'.split()\n",
    "for tree in cp.parse(tokens2):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S[-INV]\n",
      "  (Adv[+NEG] rarely)\n",
      "  (S[+INV]\n",
      "    (V[+AUX] do)\n",
      "    (NP[-WH] you)\n",
      "    (VP[] (V[-AUX, SUBCAT='intrans'] sing))))\n"
     ]
    }
   ],
   "source": [
    "tokens3 = 'rarely do you sing'.split()\n",
    "for tree in cp.parse(tokens3):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Objectives\n",
    "\n",
    "* Appreciate how feature values (attribute-values) are superior to atomic symbols as using the latter will require massive multiplications to capture real-life CFG production rules.\n",
    "\n",
    "* Understand how to represent entities as features and values and an Attribute-Value Matrix (AVM), and how the features can be nested.\n",
    "\n",
    "* Use variables as feature values to specify dependencies.\n",
    "\n",
    "* Use shared values represented as numerical indices in AVMs.\n",
    "\n",
    "* Understand subsumption and unification when explaining relationships between feature structures. Identify if a DAG $FS_A \\sqsubseteq FS_B$. Evaluate the unification of two or more DAGs $FS_A \\sqcup FS_B$.\n",
    "\n",
    "* Understand and apply the concept that if unification specializes a path $\\pi$ in $FS$, then it specializes every path $\\pi '$ equivalent to $\\pi$.\n",
    "\n",
    "* Use feature structures to built succint analyses of a wide variety of linguistic phenomena including *verb subcategorization*, *inversion constructions* and *unbounded dependency constructions*."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
