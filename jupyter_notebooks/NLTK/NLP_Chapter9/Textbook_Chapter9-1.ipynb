{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.1 - Grammatical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of automatically detecting features of words, we will change to *explicitly declaring these features*. Let's first store some features and their values using dictionaries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "kim = {\"CAT\": \"NP\", \"ORTH\": \"Kim\", \"REF\": \"k\"}\n",
    "chase = {\"CAT\": \"V\", \"ORTH\": \"chased\", \"REL\": \"chase\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both objects `kim` and `chase` have shared features, **CAT** (grammatical category) and **ORTH** (orthography, spelling). Each also has a semantically oriented feature: \n",
    "* `kim[\"REF\"]` is intended to give the referent of `kim` while \n",
    "* `chase[\"REL\"]` gives the relation expressed by `chase`\n",
    "\n",
    "Such pairings of features and values are known as **feature structures**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might want to add additional features on top of the general ones as mentioned in earlier chapters. Consider the word `chase`. \n",
    "\n",
    "The subject of the sentence is known as the **agent** while the object is known as the **patient**. Let's add them in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chase[\"AGT\"] = \"sbj\"\n",
    "chase[\"PAT\"] = \"obj\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, given a sentence *Kim chased Lee*, we want to bind the **verb's agent role to the subject** and its **patient role to the object**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORTH  => chased\n",
      "REL   => chase\n",
      "AGT   => k\n",
      "PAT   => l\n"
     ]
    }
   ],
   "source": [
    "#add a feature structure to Lee\n",
    "lee = {\"CAT\": \"NP\", \"ORTH\": \"Lee\", \"REF\": \"l\"}\n",
    "#Declare the sentence.\n",
    "sent = \"Kim chased Lee\"\n",
    "tokens = sent.split()\n",
    "\n",
    "def lex2fs(word):\n",
    "    for fs in [kim, lee, chase]:\n",
    "        if fs[\"ORTH\"] == word:\n",
    "            return fs\n",
    "\n",
    "subj, verb, obj = lex2fs(tokens[0]), lex2fs(tokens[1]), lex2fs(tokens[2])\n",
    "verb[\"AGT\"] = subj[\"REF\"]\n",
    "verb[\"PAT\"] = obj[\"REF\"]\n",
    "for k in [\"ORTH\", \"REL\", \"AGT\", \"PAT\"]:\n",
    "    print(\"%-5s => %s\" % (k, verb[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same approach can be adopted by a different verb. For the word `surprise` the subject is the **source** and the object is the **experiencer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "surprise = {\"CAT\": \"V\", \"ORTH\": \"surprised\", \"REL\": \"surprise\", \"SRC\": \"sbj\", \"EXP\" : \"obj\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syntactic Agreement\n",
    "\n",
    "`This dog` is grammatically correct while `these dog` is grammatically wrong. The correct form of that phrase is `these dogs`. Conversely, `this dogs` is also wrong. (\"this is for singlular while \"these\" is for plural nouns)\n",
    "\n",
    "`The dog runs` is grammatically correct while `The dog run` is grammatically wrong. (verb after plural verb usually has no \"s\" and vice versa). Similarly, `The dogs run` is grammatically correct while `The dogs runs` is wrong.\n",
    "\n",
    "Morphological properties of the verb co-vary with syntactic properties of the subject noun phrase. This co-variance is called **agreement**.\n",
    "\n",
    "We can make the morphological properties more explicit (We use `3` for 3rd person, `SG` for singular and `PL` for plural)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SINGULAR, 3rd person\n",
      "the   dog        run-s\n",
      "the   dog.3.SG   run-3.SG\n",
      "\n",
      "PLURAL, 3rd person\n",
      "the   dog-s      run\n",
      "the   dog.3.PL   run.3.PL\n"
     ]
    }
   ],
   "source": [
    "print(\"SINGULAR, 3rd person\")\n",
    "print(\"the   dog        run-s\")\n",
    "print(\"the   dog.3.SG   run-3.SG\")\n",
    "print()\n",
    "print(\"PLURAL, 3rd person\")\n",
    "print(\"the   dog-s      run\")\n",
    "print(\"the   dog.3.PL   run.3.PL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Introduce a CFG on the above example:\n",
    "import nltk\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "  S  -> NP VP\n",
    "  NP -> Det N\n",
    "  VP -> V \n",
    "  Det -> 'this'\n",
    "  N -> 'dog'\n",
    "  V -> 'runs'\n",
    "\"\"\")\n",
    "#This grammar generates \"This dog runs\" but it also generates other invalid sentences like \"These dog runs\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The most straightforward way to implement the constraints is to add new non-terminals and productions to the grammar\n",
    "grammar2 = nltk.CFG.fromstring(\"\"\"\n",
    "  S  -> NP_SG VP_SG\n",
    "  S  -> NP_PL VP_PL\n",
    "  NP_SG -> Det_SG N_SG\n",
    "  NP_PL -> Det_PL N_PL\n",
    "  VP_SG -> V_SG\n",
    "  VP_PL -> V_PL\n",
    "  \n",
    "  Det_SG -> 'this'\n",
    "  N_SG -> 'dog'\n",
    "  V_SG -> 'runs'\n",
    "\n",
    "  Det_PL -> 'these'\n",
    "  N_PL -> 'dog'\n",
    "  V_PL -> 'runs'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of having 1 CFG production, we now have **2 CFG productions** - one for singular and one for plural. With a small grammar, it's ugly and in larger grammars, clearly, it is inefficient. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Attributes and Constraints\n",
    "Linguistic categories have properties e.g. a noun has the property of being plural:\n",
    "\n",
    "`N[NUM=pl]`\n",
    "In this case, we introduce a new feature where a term in the category `N` has a feature called `NUM` and its value is `pl` (short for plural). We can add similar annotations to other categories and use them in lexical entries:\n",
    "\n",
    "`Det[NUM=sg] -> 'this'`\n",
    "\n",
    "`Det[NUM=pl] -> 'these'`\n",
    "\n",
    "`N[NUM=sg] -> 'dog'`\n",
    "\n",
    "`N[NUM=pl] -> 'dogs'`\n",
    "\n",
    "`V[NUM=sg] -> 'runs'`\n",
    "\n",
    "`N[NUM=pl] -> 'run'`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Previously we only allowed feature values to be explicit. Now, we relax this rule and let values be variable.**\n",
    "\n",
    "```S  -> NP[NUM=?n] VP[NUM=?n]\n",
    "NP -> Det[NUM=?n] N[NUM=?n]\n",
    "VP -> V[NUM=?n])```\n",
    "\n",
    "We use `?n` as a variable over explicit values of `NUM`, `sg` or `pl`. Whatever the value `?n` takes in the first term in the frist production, the 2nd value **must** take the same value. This applies to `S  -> NP[NUM=?n] VP[NUM=?n]` and also `NP -> Det[NUM=?n] N[NUM=?n]`.\n",
    "\n",
    "We can also *underspecify* this attribute's value to let it agree in number with whatever noun it combines with:\n",
    "\n",
    "`Det[NUM=?n] -> 'the' | 'some' | 'several' `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% start S\n",
      "# ###################\n",
      "# Grammar Productions\n",
      "# ###################\n",
      "# S expansion productions\n",
      "S -> NP[NUM=?n] VP[NUM=?n]\n",
      "# NP expansion productions\n",
      "NP[NUM=?n] -> N[NUM=?n] \n",
      "NP[NUM=?n] -> PropN[NUM=?n] \n",
      "NP[NUM=?n] -> Det[NUM=?n] N[NUM=?n]\n",
      "NP[NUM=pl] -> N[NUM=pl] \n",
      "# VP expansion productions\n",
      "VP[TENSE=?t, NUM=?n] -> IV[TENSE=?t, NUM=?n]\n",
      "VP[TENSE=?t, NUM=?n] -> TV[TENSE=?t, NUM=?n] NP\n",
      "# ###################\n",
      "# Lexical Productions\n",
      "# ###################\n",
      "Det[NUM=sg] -> 'this' | 'every'\n",
      "Det[NUM=pl] -> 'these' | 'all'\n",
      "Det -> 'the' | 'some' | 'several'\n",
      "PropN[NUM=sg]-> 'Kim' | 'Jody'\n",
      "N[NUM=sg] -> 'dog' | 'girl' | 'car' | 'child'\n",
      "N[NUM=pl] -> 'dogs' | 'girls' | 'cars' | 'children' \n",
      "IV[TENSE=pres,  NUM=sg] -> 'disappears' | 'walks'\n",
      "TV[TENSE=pres, NUM=sg] -> 'sees' | 'likes'\n",
      "IV[TENSE=pres,  NUM=pl] -> 'disappear' | 'walk'\n",
      "TV[TENSE=pres, NUM=pl] -> 'see' | 'like'\n",
      "IV[TENSE=past] -> 'disappeared' | 'walked'\n",
      "TV[TENSE=past] -> 'saw' | 'liked'\n"
     ]
    }
   ],
   "source": [
    "nltk.data.show_cfg('grammars/book_grammars/feat0.fcfg')\n",
    "#In the result, notice how the variables are used for the NUM and the TENSE feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see there are other features too including the `TENSE` feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|.Kim .like.chil.|\n",
      "Leaf Init Rule:\n",
      "|[----]    .    .| [0:1] 'Kim'\n",
      "|.    [----]    .| [1:2] 'likes'\n",
      "|.    .    [----]| [2:3] 'children'\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|[----]    .    .| [0:1] PropN[NUM='sg'] -> 'Kim' *\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|[----]    .    .| [0:1] NP[NUM='sg'] -> PropN[NUM='sg'] *\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|[---->    .    .| [0:1] S[] -> NP[NUM=?n] * VP[NUM=?n] {?n: 'sg'}\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|.    [----]    .| [1:2] TV[NUM='sg', TENSE='pres'] -> 'likes' *\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|.    [---->    .| [1:2] VP[NUM=?n, TENSE=?t] -> TV[NUM=?n, TENSE=?t] * NP[] {?n: 'sg', ?t: 'pres'}\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|.    .    [----]| [2:3] N[NUM='pl'] -> 'children' *\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|.    .    [----]| [2:3] NP[NUM='pl'] -> N[NUM='pl'] *\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|.    .    [---->| [2:3] S[] -> NP[NUM=?n] * VP[NUM=?n] {?n: 'pl'}\n",
      "Feature Single Edge Fundamental Rule:\n",
      "|.    [---------]| [1:3] VP[NUM='sg', TENSE='pres'] -> TV[NUM='sg', TENSE='pres'] NP[] *\n",
      "Feature Single Edge Fundamental Rule:\n",
      "|[==============]| [0:3] S[] -> NP[NUM='sg'] VP[NUM='sg'] *\n",
      "(S[]\n",
      "  (NP[NUM='sg'] (PropN[NUM='sg'] Kim))\n",
      "  (VP[NUM='sg', TENSE='pres']\n",
      "    (TV[NUM='sg', TENSE='pres'] likes)\n",
      "    (NP[NUM='pl'] (N[NUM='pl'] children))))\n"
     ]
    }
   ],
   "source": [
    "#trace of feature-based chart parser.\n",
    "tokens = \"Kim likes children\".split()\n",
    "from nltk import load_parser\n",
    "cp = load_parser('grammars/book_grammars/feat0.fcfg', trace=2)\n",
    "for tree in cp.parse(tokens):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terminology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple values like `sg` and `pl` are **atomic** feature values - they cannot be decomposed to subparts. A special case of atomic values are **boolean** values, that take the value true or false. For example, we might want to distinguish *auxiliary verbs* like `can`, `may`, `will` and `do` with the boolean feature `AUX` then the production \n",
    "\n",
    "`V[TENSE=pres, aux=+] -> 'can'` means `can` receives the value`pres` for `TENSE` and `+` for `AUX`. Some representative productions are:\n",
    "\n",
    "`V[TENSE=pres, +aux] -> 'can'`\n",
    "\n",
    "`V[TENSE=pres, +aux] -> 'may'`\n",
    "\n",
    "`V[TENSE=pres, -aux] -> 'walks'`\n",
    "\n",
    "`V[TENSE=pres, -aux] -> 'likes'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another more radical way is to represent the whole category as a bundle of features. For example, `N[NUM=sg]` contains POS information which can be represented as `POS=N`. Hence an alternative notation is `[POS=N, NUM=sg]`.\n",
    "\n",
    "We can also group ***agreement features*** as a distinguished part of a category, serving as the value of `AGR`. In this case we say `AGR` has a **complex** value. It can be expressed as an **attribute value matrix (AVM)**.\n",
    "```\n",
    "[POS = N           ]\n",
    "[                  ]\n",
    "[AGR = [PER = 3   ]]\n",
    "[      [NUM = pl  ]]\n",
    "[      [GND = fem ]]\n",
    "```\n",
    "Representing 3rd person, plural, feminine affinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
