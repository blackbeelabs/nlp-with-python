{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Semantics of English Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compositional Semantics in Feature-Based Grammar\n",
    "\n",
    "One of the guiding ideas of building logical form for a question instead of just constructing SQL query is the **Principle of Compositionality**.\n",
    "\n",
    "Principle of Compositionality says that the meaning of a whole is defined as the meaning of its parts and of the way they are syntactically combined.\n",
    "\n",
    "The idea is illustrated as follows:\n",
    "\n",
    "`bark        -> <\\x.bark(x)>`\n",
    "\n",
    "`Cyril       -> <Cyril>`\n",
    "\n",
    "`Cyril barks -> <bark(Cyril)>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The $\\lambda$-Calculus\n",
    "\n",
    "The mathematical notation $\\left\\{ w \\mid w \\in V \\& P(w)\\right\\}$ denotes the set of all $w$ such that $w$ is an element of $V$ and $w$ has property $P$. We can add the **$\\lambda$ operator to achieve the same effect in first-order logic. The $\\lambda$ counterpart to the above statement is $\\lambda w.(V(w) \\wedge P(w))$\n",
    "\n",
    "$\\lambda$ is a binding operator, just as the first-order logic quantifiers are. Given the open formula $(walk(x) \\wedge chew\\_gum(x))$, we can bind the variable $x$ with the $\\lambda$-operator to form $\\lambda x.(walk(x) \\wedge chew\\_gum(x))$. The NLTK equivalent of this operator is `\\x.(walk(x) & chew_gum(x))`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<LambdaExpression \\x.(walk(x) & chew_gum(x))>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_expr = nltk.sem.Expression.fromstring\n",
    "expr = read_expr(r'\\x.(walk(x) & chew_gum(x))')\n",
    "expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expr.free()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\x.(walk(x) & chew_gum(y))\n"
     ]
    }
   ],
   "source": [
    "print(read_expr(r'\\x.(walk(x) & chew_gum(y))'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binding the variables in an expression is called **$\\lambda$-abstraction**. Here is an example of a $\\lambda$-extract: \"be an $x$ such that $x$ walks and $x$ chews gum\" or \"have the property of walking and chewing gum\". It has often been suggested that $\\lambda$-abstracts are good representations for verb phrases (or subjectless clauses), particularly when arguments occur as arguments in their own right:\n",
    "\n",
    "1. To walk and chew gum is hard\n",
    "2. `hard(\\x.walk(x) & chew_gum(x)))`\n",
    "\n",
    "So the general picture is this: given an open formula $\\phi$ with free variable $x$, abstracting over $x$ yields a property expression $\\lambda x.\\phi$ - the property of being $x$ such that $\\phi$. Formally,\n",
    "\n",
    "If $\\alpha$ is of type $\\tau$, and $x$ is a variable of type $e$, then `\\x.`$\\alpha$ is of type $\\left<e, \\tau\\right>$. The above sentence (to walk and chew gum is hard) is a case where we say something about a property, namely saying that it is hard. However we usually attribute a property to an individual. In fact if $\\phi$ is an open formula then the abstract $\\lambda x.\\phi$ can be used as a unary predicate. E.g. \n",
    "\n",
    "`\\x.(walk(x) & chew_gum(x)) (gerald)` and now it says that Gerald has the property of walking and chewing gum, which has the same meaning as `(walk(gerald) & chew_gum(gerald))`.\n",
    "\n",
    "What we have done here is remove the `\\x` from the expression in the beginning and replaced all occurences of `x` with `gerald`. \n",
    "\n",
    "We say $\\alpha \\begin{bmatrix}\\beta/x \\end{bmatrix}$ is the operation of replacing all free occurences of $x$ in $\\alpha$ with the expression $\\beta$, so `(walk(x) & chew_gum(x)) [gerald/x]` is now the same expression as `(walk(gerald) & chew_gum(gerald))`. This operation is called **$\\beta$-reduction** and there is such a functionality in NLTK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\x.(walk(x) & chew_gum(x))(gerald)\n"
     ]
    }
   ],
   "source": [
    "expr = read_expr(r'\\x.(walk(x) & chew_gum(x)) (gerald)')\n",
    "print(expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(walk(gerald) & chew_gum(gerald))\n"
     ]
    }
   ],
   "source": [
    "print(expr.simplify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that earlier the body of the $\\lambda$ expression is an open formula but it is not restricted to just this. It can be any open formula. Here is an example with two $\\lambda$s:\n",
    "`\\x.\\y.(dog(x) & own(y, x))` and this is an example of a binary predicate. In NLTK, the nested $\\lambda$s `\\x.\\y.` should be written in the abbreviated form `\\x y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\y.(dog(cyril) & own(y,cyril))\n"
     ]
    }
   ],
   "source": [
    "print(read_expr(r'\\x.\\y.(dog(x) & own(y, x)) (cyril)').simplify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(dog(cyril) & own(angus,cyril))\n"
     ]
    }
   ],
   "source": [
    "print(read_expr(r'\\x.\\y.(dog(x) & own(y, x)) (cyril, angus)').simplify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All our $\\lambda$ abstracts involve the first-order variables, `x` and `y`, variables of type $e$. But suppose we want to treat one abstract, say `x.walk(x)` as the *argument* of another $\\lambda$ abstract, we might try this:\n",
    "\n",
    "`\\y.y(angus)(\\x.walk(x))`\n",
    "but since `y` is of type $e$, `\\y.y(angus)` only applies to arguments of type $e$ while `\\x.walk(x)` is of type $\\left<e, t\\right>$. Instead we need to allow abstraction over variables of higher type.\n",
    "\n",
    "Let's use variables `P` and `Q` as variables of type $\\left<e,t\\right>$ and then we can have an abstract such as `P.P(angus)`. Since `P` is of type $\\left<e,t\\right>$, the whole abstract is of type $\\left< \\left<e, t\\right>, t\\right>$. Then `\\P.P(angus)(\\x.walk(x))` is legal, and can be simplified via $\\beta$-reduction to `\\x.walk(x) (angus)` and then again to `walk(angus)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When carrying out $\\beta$-reduction, come care needs to be taken with variables. Consider \n",
    "\n",
    "- `\\y.see(y, x)`\n",
    "- `\\y.see(y, z)`\n",
    "\n",
    "Suppose now we apply the $\\lambda$-term `\\P.exists x.P(x)` to each of these terms:\n",
    "\n",
    "- `P.exists x.P(x)(\\y.see(y, x))`\n",
    "- `P.exists x.P(x)(\\y.see(y, z))`\n",
    "\n",
    "Observe if we let the free variable `x` in `\\y.see(y, x)` fall inside the scope of the existential quantifier in `P.exists x.P(x)(\\y.see(y, x))` then after reduction, the result will be `exists.x(see(x, x))`. Contrast this with the second expression: `exists.x(see(x, z))`. The meanings are different The first is `x` seeing himself while the second is `x` seeing some other person `z`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that given any variable-binding expression($\\exists$, $\\lambda$ or $\\forall$), the name chosen for the bound variable is completely arbitrary. `exists x.P(x)` and `exists(y).p(y)` are equivalent: they are called **$\\alpha$-equivalent** or **alphabetic variants**. The process of re-labelling bound variables is **$\\alpha$-conversion**. When we test for equality of `VariableBinderExpression`s in the NLTK `logic` module, we are in fact testing for $\\alpha$-equivalence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ExistsExpression exists x.P(x)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expr1 = read_expr('exists x.P(x)')\n",
    "expr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ExistsExpression exists z.P(z)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expr2 = expr1.alpha_convert(nltk.sem.Variable('z'))\n",
    "expr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expr1 == expr2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When $\\beta$-reduction is carried out on an application `f(a)`, we check if there are free variables in `a` which also occur as bound variables in any subterms of `f`. If `x` is free in `a` and that `f` contains the subterm `exists x.P(x)`. In this case, we produce an alphabetic variant of `exists x.P(x)` say `exists z1.P(z1)` and then carry on with the reduction. This relabelling is automatically done in `logic`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\\P.exists x.P(x))(\\y.see(y,x))\n"
     ]
    }
   ],
   "source": [
    "expr3 = read_expr('\\P.(exists x.P(x))(\\y.see(y, x))')\n",
    "print(expr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exists z1.see(z1,x)\n"
     ]
    }
   ],
   "source": [
    "print(expr3.simplify())\n",
    "#returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantified NPs\n",
    "\n",
    "Let's now add quantifiers to the mix. We would like to express the sentence \n",
    "\n",
    "`A dog barks` to the form `exists x.(dog(x) & bark(x))`. The key step to this is to give a semantic representation to the quantified `NPS` *a dog* so that it can be combined with `bark` to give the logical statement. First, let's make the subject's `sem` value act as the function expression rather than the argument (this is sometimes called **type-raising**). Now, we are looking for a way of instantiating `?np` so that `[SEM=<?np(\\x.bark(x))>]` is equivalent to `[SEM=<exists x.(dog(x) & bark(x))>]`. This looks like carrying out $\\beta$-reduction in $\\lambda$-calculus. In other words, we want a $\\lambda$ term $M$ to replace `?np` so that applying $M$ to `bark` yields `exists x.(dog(x) & bark(x))`. To do this, replace the occurence `bark` by a predicate variable `P` and bind the variable to $\\lambda$:\n",
    "\n",
    "- `P.exists x.(dog(x) & P(x))`\n",
    "\n",
    "and this is of type $\\left<e, \\left<e,t\\right>\\right>$. We will take this to be tye type of `NPS` in general. To illustrate further, a universally quantified `NP` will look like:\n",
    "\n",
    "`\\P.all x.(dog(x) -> P(x))`\n",
    "\n",
    "By combining the semantics of the determiner $\\alpha$ with the semantics of `dog`, we get:\n",
    "\n",
    "`\\Q P.exists x.(Q(x) & P(x))`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, \n",
    "\n",
    "Applying `\\Q P.exists x.(Q(x) & P(x))`  as a function expression to `dog` yields `P.exists x.(dog(x) & P(x))` and carrying out $\\beta$-reduction yields `exists x.(dog(x) & bark(x))`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transistive Verbs\n",
    "\n",
    "The next challenge is to deal with transistive verbs, like:\n",
    "\n",
    "`Angus chases a dog.`\n",
    "\n",
    "The output semantics we want to build is\n",
    "\n",
    "`exists x.(dog(x) & chase(angus, x))`. Here's a semantic expression for `chases a dog`:\n",
    "\n",
    "`\\y.exists x.(dog(x) & chase(y, x))`\n",
    "\n",
    "Think of this as the property of being a $y$ such that for some $dog$ $x$, $y$ chases $x$. More basically, $y$ chases a dog.\n",
    "\n",
    "Let's carry out the inverse of $\\beta$-reduction on the above expression giving:\n",
    "\n",
    "`\\P.exists x.(dog(x) & P(x))(\\z.chase(y, z))`\n",
    "\n",
    "It involves the quantified `NP` representation from above to `\\z.chase(y,z)` and is equivalent via $\\beta$-reduction to `exists x.(dog(x) & chase(y, x))`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's replace the function expression by a variable `x` of the same type as an `NP`, that is of type $\\left< \\left<e,t\\right>, t\\right>$.\n",
    "\n",
    "`X(\\z.chase(y, z))`\n",
    "\n",
    "We finally give `chases` the semantic representation:\n",
    "\n",
    "`\\X y.X(\\x.chase(y, x))`\n",
    "\n",
    "If the last expression is applied to `\\P.exists x.(dog(x) & P(x))` then the result after $\\beta$-reduction is equivalent to what we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\\X x.X(\\y.chase(x,y)))(\\P.exists x.(dog(x) & P(x)))\n"
     ]
    }
   ],
   "source": [
    "read_expr = nltk.sem.Expression.fromstring\n",
    "tvp = read_expr(r'\\X x.X(\\y.chase(x,y))')\n",
    "np = read_expr(r'(\\P.exists x.(dog(x) & P(x)))')\n",
    "vp = nltk.sem.ApplicationExpression(tvp, np)\n",
    "print(vp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\x.exists z2.(dog(z2) & chase(x,z2))\n"
     ]
    }
   ],
   "source": [
    "print(vp.simplify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For proper nouns, we re-interpret them such that they are also function expressions, like quantified `NP`s:\n",
    "\n",
    "`\\P.P(angus)`\n",
    "\n",
    "This denotes the characteristic function corresponding to the set of all properties which are true of Angus. Converting from an individual constant `angus` to `\\P.P(angus)` is also considered type-raising, and allows us to replace a Boolean-valued application such as `\\x.walk(x)(angus)` with an equivalent function application `\\P.P(angus)(\\x.walk(x))`. Using $\\beta$-reduction, both expressions reduce to `walk(angus)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all z4.(dog(z4) -> exists z3.(bone(z3) & give(angus,z3,z4)))\n"
     ]
    }
   ],
   "source": [
    "from nltk import load_parser\n",
    "parser = load_parser('grammars/book_grammars/simple-sem.fcfg', trace=0)\n",
    "sentence = 'Angus gives a bone to every dog'\n",
    "tokens = sentence.split()\n",
    "for tree in parser.parse(tokens):\n",
    "    print(tree.label()['SEM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparing result with textbook result, similar due to alphabetic variants.\n",
    "#all z4.(dog(z4) -> exists z3.(bone(z3) & give(angus,z3,z4)))\n",
    "#all z2.(dog(z2) -> exists z1.(bone(z1) & give(angus,z1,z2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S[SEM=<walk(irene)>]\n",
      "  (NP[-LOC, NUM='sg', SEM=<\\P.P(irene)>]\n",
      "    (PropN[-LOC, NUM='sg', SEM=<\\P.P(irene)>] Irene))\n",
      "  (VP[NUM='sg', SEM=<\\x.walk(x)>]\n",
      "    (IV[NUM='sg', SEM=<\\x.walk(x)>, TNS='pres'] walks)))\n",
      "(S[SEM=<exists z5.(ankle(z5) & bite(cyril,z5))>]\n",
      "  (NP[-LOC, NUM='sg', SEM=<\\P.P(cyril)>]\n",
      "    (PropN[-LOC, NUM='sg', SEM=<\\P.P(cyril)>] Cyril))\n",
      "  (VP[NUM='sg', SEM=<\\x.exists z5.(ankle(z5) & bite(x,z5))>]\n",
      "    (TV[NUM='sg', SEM=<\\X x.X(\\y.bite(x,y))>, TNS='pres'] bites)\n",
      "    (NP[NUM='sg', SEM=<\\Q.exists x.(ankle(x) & Q(x))>]\n",
      "      (Det[NUM='sg', SEM=<\\P Q.exists x.(P(x) & Q(x))>] an)\n",
      "      (Nom[NUM='sg', SEM=<\\x.ankle(x)>]\n",
      "        (N[NUM='sg', SEM=<\\x.ankle(x)>] ankle)))))\n"
     ]
    }
   ],
   "source": [
    "sents = ['Irene walks', 'Cyril bites an ankle']\n",
    "grammar_file = 'grammars/book_grammars/simple-sem.fcfg'\n",
    "for results in nltk.interpret_sents(sents, grammar_file):\n",
    "    for (synrep, semrep) in results:\n",
    "        print(synrep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have seen how to convert English sentences to logical forms, and now see how logical forms can be checked as true or false in a model. Now, we can check the truth value of English sentences in a given model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all z6.(boy(z6) -> see(cyril,z6))\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "v = \"\"\"\n",
    "bertie => b\n",
    "olive => o\n",
    "cyril => c\n",
    "boy => {b}\n",
    "girl => {o}\n",
    "dog => {c}\n",
    "walk => {o, c}\n",
    "see => {(b, o), (c, b), (o, c)}\n",
    "\"\"\"\n",
    "val = nltk.Valuation.fromstring(v)\n",
    "g = nltk.Assignment(val.domain)\n",
    "m = nltk.Model(val.domain, val)\n",
    "sent = 'Cyril sees every boy'\n",
    "grammar_file = 'grammars/book_grammars/simple-sem.fcfg'\n",
    "results = nltk.evaluate_sents([sent], grammar_file, m, g)[0]\n",
    "for (syntree, semrep, value) in results:\n",
    "    print(semrep)\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantifier Ambiguity Revisited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
